<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>The Perron-Frobenius Theorem | Tao Deng</title> <meta name="author" content="Tao Deng"> <meta name="description" content="a detailed proof of the PF theorem and an application"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A7%AC&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://torydeng.github.io/blog/2023/perron-frobenius/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Tao </span>Deng</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching</a> </li> <li class="nav-item "> <a class="nav-link" href="/_pages/cv-eng/">CV (English)</a> </li> <li class="nav-item "> <a class="nav-link" href="/_pages/cv-chi/">CV (Chinese)</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Perron-Frobenius Theorem</h1> <p class="post-meta">December 8, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/matrix"> <i class="fa-solid fa-hashtag fa-sm"></i> matrix</a>   <a href="/blog/tag/eigenvalue"> <i class="fa-solid fa-hashtag fa-sm"></i> eigenvalue</a>   <a href="/blog/tag/spectral-radius"> <i class="fa-solid fa-hashtag fa-sm"></i> spectral-radius</a>     ·   <a href="/blog/category/mathematics"> <i class="fa-solid fa-tag fa-sm"></i> mathematics</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>The <a href="https://en.wikipedia.org/wiki/Perron%E2%80%93Frobenius_theorem" rel="external nofollow noopener" target="_blank">Perron-Frobenius Theorem</a> establishes powerful assertions about the eigenvalues and eigenvectors of certain types of matrices that are non-negative, which are incredibly insightful when dealing with dynamical systems, economics, demography, and beyond. This post offers an accessible proof of the theorem, which is carefully curated from lecture contents of CIE6002 Matrix Analysis.</p> <h2 id="notations">Notations</h2> <ul> <li>\(\boldsymbol{A} \in \mathbb{R}^{m \times m}\): an \(m\) by \(m\) matrix.</li> <li>\(\Vert \cdot \Vert\): in most cases it refers to matrix norm.</li> <li>\(\displaystyle \Vert \boldsymbol{A} \Vert_1 = \max_{j=1,2,\ldots,m} \sum_{i=1}^{m} \boldsymbol{A}_{ij}\): the maximum absolute column sum of the matrix.</li> <li>\(\displaystyle \Vert \boldsymbol{A} \Vert_\infty = \max_{i=1,2,\ldots,m} \sum_{j=1}^{m} \boldsymbol{A}_{ij}\): the maximum absolute row sum of the matrix.</li> </ul> <h2 id="the-theorem">The theorem</h2> <p>Let \(\boldsymbol{A} \in \mathbb{R}^{n \times n}\) be positive. That is, \(\boldsymbol{A}_{ij} &gt; 0, \forall 1 \le i,j \le m\). The <em>spectral radius</em> is defined as</p> \[\rho(\boldsymbol{A}) = \max_{i} |\lambda_i|\] <p>where \(\lambda_i\) is the \(i\)-th eigenvalue of \(\boldsymbol{A}\). Then</p> <ol> <li>\(\rho(\boldsymbol{A}) &gt; 0\), and \(\rho(\boldsymbol{A})\) is an eigenvalue of \(\boldsymbol{A}\);</li> <li>The corresponding eigenvector of \(\rho(\boldsymbol{A})\) is positive (or negative);</li> <li>\(\lvert \lambda \rvert &lt; \rho(\boldsymbol{A})\) for any \(\boldsymbol{A}\)’s eigenvalue \(\lambda \ne \rho(\boldsymbol{A})\);</li> <li>\(\operatorname{dim}(\operatorname{Null}(\boldsymbol{A} - \rho(\boldsymbol{A})\boldsymbol{I})) = 1\).</li> </ol> <h2 id="some-lemmas">Some lemmas</h2> <p><strong>Lemma 1:</strong> \(\rho(\boldsymbol{A}) \le \Vert \boldsymbol{A} \Vert\) for any matrix norm \(\Vert\cdot\Vert.\)</p> <p><strong>Proof:</strong> Let \(\boldsymbol{Av} = \lambda \boldsymbol{v}\) with \(\lvert\lambda\rvert = \rho(\boldsymbol{A})\). Let \(\boldsymbol{V} = \boldsymbol{v} \boldsymbol{1}^\top \in \mathbb{R}^{m \times m}\). Then</p> \[\begin{align*} &amp;\boldsymbol{AV} = \lambda \boldsymbol{V} \\ \Rightarrow &amp;\Vert\boldsymbol{AV}\Vert = \lvert \lambda \rvert \cdot \Vert\boldsymbol{V}\Vert \le \Vert\boldsymbol{A}\Vert \cdot \Vert\boldsymbol{V}\Vert \\ \Rightarrow &amp; \lvert \lambda \rvert = \rho(\boldsymbol{A}) \le \Vert\boldsymbol{A}\Vert. \end{align*}\] <hr> <p><strong>Lemma 2:</strong> Given \(\varepsilon &gt; 0\). There exists a matrix norm \(\Vert\cdot\Vert\) s.t. \(\rho(\boldsymbol{A}) \le \Vert\boldsymbol{A}\Vert \le \rho(\boldsymbol{A}) + \varepsilon \Rightarrow \rho(\boldsymbol{A}) = \inf_{\Vert\cdot\Vert} \Vert\boldsymbol{A}\Vert\).</p> <p><strong>Proof:</strong> The Schur triangularization of \(\boldsymbol{A}\) is \(\boldsymbol{A} = \boldsymbol{UTU}^\top\), where \(\boldsymbol{U}\) is unitary and diagonals \(\lambda_1, \ldots, \lambda_m\) of \(\boldsymbol{T}\) are eigenvalues of \(\boldsymbol{A}\). Define</p> \[\begin{align*} \Vert\boldsymbol{A}\Vert &amp;\triangleq \Vert(\boldsymbol{UD}_t^{-1})^{-1}\boldsymbol{A}(\boldsymbol{UD}_t^{-1})\Vert_1 \\ &amp;= \Vert\boldsymbol{D}_t \boldsymbol{U}^\top \boldsymbol{AUD}_t^{-1}\Vert_1 \\ &amp;= \Vert\boldsymbol{D}_t \boldsymbol{T} \boldsymbol{D}_t^{-1}\Vert_1 \\ &amp;= \Vert\begin{bmatrix} \lambda_1 &amp; t^{-1}T_{12} &amp; t^{-2}T_{13} &amp; \cdots &amp; t^{-m+1}T_{1m}\\ &amp; \lambda_2 &amp; t^{-1}T_{13} &amp; \cdots &amp; t^{-m+2}T_{2m}\\ &amp; &amp; \lambda_3 &amp; \cdots &amp; t^{-m+3}T_{3m} \\ &amp; &amp; &amp; \ddots &amp; \vdots \\ &amp; &amp; &amp; &amp; \lambda_m \end{bmatrix}\Vert_1 \\ &amp;\le \rho(\boldsymbol{A}) + \varepsilon \quad \text{for large}\ t \end{align*}\] <p>where \(\boldsymbol{D}_t = \begin{bmatrix} t^1 &amp; &amp; &amp; \\ &amp; t^2 &amp; &amp; \\ &amp; &amp; \ddots &amp; \\ &amp; &amp; &amp; t^m \end{bmatrix}.\)</p> <hr> <p><strong>Lemma 3:</strong> \(\lim_{k \to \infty} \boldsymbol{A}^k = \boldsymbol{0} \iff \rho(\boldsymbol{A}) &lt; 1.\)</p> <p><strong>Proof:</strong> The “\(\Rightarrow\)” part. Let \(\boldsymbol{Av} = \lambda \boldsymbol{v}\) for any eigenvalue \(\lambda\) of \(\boldsymbol{A}\). Then</p> \[\boldsymbol{A}^k\boldsymbol{v} = \lambda^k \boldsymbol{v} \Rightarrow \lambda^k \to 0 \Rightarrow |\lambda| &lt; 1 \Rightarrow \rho(\boldsymbol{A}) &lt; 1.\] <p>The “\(\Leftarrow\)” part. By Lemma 2, \(\exists\ \Vert\cdot\Vert\) s.t. \(\Vert\boldsymbol{A}\Vert &lt; 1.\) Then</p> \[0 \le \lim_{k \to \infty} \Vert\boldsymbol{A}^k\Vert \le \lim_{k \to \infty} \Vert\boldsymbol{A}\Vert^k = 0 \Rightarrow \lim_{k \to \infty} \boldsymbol{A}^k = \boldsymbol{0}.\] <hr> <p><strong>Lemma 4:</strong> Let \(\boldsymbol{A}, \boldsymbol{B} \in \mathbb{R}^{m \times m}\) and \(\vert \boldsymbol{A} \vert \le \boldsymbol{B}\) element-wise. Then</p> \[\rho(\boldsymbol{A}) \le \rho(\boldsymbol{\vert A \vert}) \le \rho(\boldsymbol{B}).\] <p><strong>Proof:</strong></p> \[\begin{align*} &amp;\boldsymbol{A} \le \boldsymbol{\vert A \vert} \le \boldsymbol{B} \\ \Rightarrow&amp; \boldsymbol{A}^k \le \boldsymbol{\vert A \vert}^k \le \boldsymbol{B}^k \\ \Rightarrow&amp; \Vert \boldsymbol{A}^k \Vert_F \le \Vert \boldsymbol{\vert A \vert}^k \Vert_F \le \Vert \boldsymbol{B}^k \Vert_F \\ \Rightarrow&amp; \Vert \boldsymbol{A}^k \Vert_F^{1/k} \le \Vert \boldsymbol{\vert A \vert}^k \Vert_F^{1/k} \le \Vert \boldsymbol{B}^k \Vert_F^{1/k} \\ \Rightarrow&amp; \rho(\boldsymbol{A}) \le \rho(\boldsymbol{\vert A \vert}) \le \rho(\boldsymbol{B}). \end{align*}\] <p>The last step is given by Theorem 1.</p> <p><strong>Corollary 4.1:</strong> Let \(\boldsymbol{A} \ge \boldsymbol{0}\) element-wise. Then for any principal submatrix of \(\boldsymbol{A}\), denoted as \(\tilde{\boldsymbol{A}}\), we have \(\rho(\tilde{\boldsymbol{A}}) \le \rho(\boldsymbol{A}) \Rightarrow \max_{i} \boldsymbol{A}_{ii} \le \rho(\boldsymbol{A})\).</p> <hr> <p><strong>Lemma 5:</strong> Let \(\boldsymbol{A} \ge \boldsymbol{0}\) element-wise. If row (column) sums of \(\boldsymbol{A}\) are constant, then \(\rho(\boldsymbol{A}) = \Vert \boldsymbol{A} \Vert_\infty\) ($\rho(\boldsymbol{A}) = \Vert \boldsymbol{A} \Vert_1$).</p> <p><strong>Proof:</strong> Suppose \(\boldsymbol{A1} = \alpha \boldsymbol{1}\) where \(\alpha \ge 0\) is the row sum, and thus is an eigenvalue of \(\boldsymbol{A}\). So \(\alpha \le \rho(\boldsymbol{A})\). But \(\alpha = \Vert \boldsymbol{A} \Vert_\infty \ge \rho(\boldsymbol{A})\), so \(\rho(\boldsymbol{A}) = \Vert \boldsymbol{A} \Vert_\infty.\) The column sum case is similar.</p> <hr> <p><strong>Lemma 6:</strong> Let \(\boldsymbol{A} \ge \boldsymbol{0}\) element-wise. Then</p> \[\min_{i = 1, \ldots, m} \sum_{j = 1}^m \boldsymbol{A}_{ij} \le \rho(\boldsymbol{A}) \le \Vert \boldsymbol{A} \Vert_\infty,\ \min_{j = 1, \ldots, m} \sum_{i = 1}^m \boldsymbol{A}_{ij} \le \rho(\boldsymbol{A}) \le \Vert \boldsymbol{A} \Vert_1\] <p><strong>Proof:</strong> Let</p> \[\alpha = \min_{i = 1, \ldots, m} \sum_{j = 1}^m \boldsymbol{A}_{ij} \ne 0.\] <p>\(\alpha = 0\) is a trivial case, so assume \(\alpha \ne 0\). Construct a new matrix \(\boldsymbol{B}\) by multiplying \(\alpha / \sum_{j=1}^m \boldsymbol{A}_{ij}\) to each \(i\)-th row of \(\boldsymbol{A}\).</p> <p>So \(\boldsymbol{0} \le \boldsymbol{B} \le \boldsymbol{A}\) element-wise, and \(\boldsymbol{B}\) has a constant row sum equal to \(\alpha \Rightarrow \alpha = \rho(\boldsymbol{B}) \le \rho(\boldsymbol{A})\) by Lemma 4 and 5. \(\rho(\boldsymbol{A}) \le \Vert \boldsymbol{A} \Vert_\infty\) by Lemma 1. The column sum case is similar.</p> <hr> <p><strong>Lemma 7:</strong> Let \(\boldsymbol{A} &gt; \boldsymbol{0}\) element-wise. Suppose \(\boldsymbol{Ax} = \lambda \boldsymbol{x}\), and \(\vert \lambda \vert = \rho(\boldsymbol{A})\). Then \(\exists\ \theta \in \mathbb{R}\) s.t. \(e^{-j\theta} \boldsymbol{x} = \vert \boldsymbol{x} \vert &gt; \boldsymbol{0}\) element-wise. Here \(j = \sqrt{-1}\).</p> <p><strong>Proof:</strong> \(\vert \boldsymbol{Ax} \vert = \vert \lambda \vert \vert \boldsymbol{x} \vert = \rho(\boldsymbol{A}) \vert \boldsymbol{x} \vert\). By Theorem 3, \(\boldsymbol{A} \vert \boldsymbol{x} \vert = \rho(\boldsymbol{A}) \vert \boldsymbol{x} \vert\). So \(\vert \boldsymbol{Ax} \vert = \boldsymbol{A} \vert \boldsymbol{x} \vert\) and \(\vert \boldsymbol{x} \vert &gt; \boldsymbol{0}\). For any \(1 \le i \le m\),</p> \[[\vert \boldsymbol{Ax} \vert]_i = \left\vert \sum_{j=1}^m \boldsymbol{A}_{ik} \boldsymbol{x}_k \right\vert = \sum_{k=1}^m \boldsymbol{A}_{ik} \vert \boldsymbol{x}_k \vert\] <p>For any \(\boldsymbol{x}_k \in \mathbb{C}, \boldsymbol{x}_k = \vert \boldsymbol{x}_k \vert e^{j\theta_k} = \vert \boldsymbol{x}_k \vert \cos(\theta_k) + \vert \boldsymbol{x}_k \vert \sin(\theta_k) \cdot j\). So</p> \[\begin{align*} &amp;\left\vert \sum_{j=1}^m \boldsymbol{A}_{ik} \boldsymbol{x}_k \right\vert = \sum_{k=1}^m \boldsymbol{A}_{ik} \vert \boldsymbol{x}_k \vert \\ \Rightarrow&amp; \left(\sum_{j=1}^m \boldsymbol{A}_{ik} \boldsymbol{x}_k\right) e^{-j\theta} = \sum_{k=1}^m \boldsymbol{A}_{ik} \boldsymbol{x}_k e^{-j\theta_k} \\ \Rightarrow&amp; \sum_{j=1}^m \boldsymbol{A}_{ik} \boldsymbol{x}_k e^{-j\theta} = \sum_{k=1}^m \boldsymbol{A}_{ik} \boldsymbol{x}_k e^{-j\theta_k} \\ \Rightarrow&amp; \theta_k = \theta, k=1, \ldots, m. \end{align*}\] <h2 id="some-theorems">Some theorems</h2> <p><strong>Theorem 1:</strong> \(\rho(\boldsymbol{A}) = \lim_{k \to \infty} \Vert \boldsymbol{A}^k \Vert^{1/k}\) for any matrix norm.</p> <p><strong>Proof:</strong> The aim is to show \(0 \le \Vert \boldsymbol{A}^k \Vert^{1/k} - \rho(\boldsymbol{A}) \le \varepsilon\) for large \(k\).</p> <p>To see this, \(\rho^k(\boldsymbol{A}) = \rho(\boldsymbol{A^k}) \le \Vert \boldsymbol{A}^k \Vert\) by Lemma 2. Thus \(\rho(\boldsymbol{A}) \le \Vert \boldsymbol{A}^k \Vert^{1/k} \Rightarrow 0 \le \Vert \boldsymbol{A}^k \Vert^{1/k} - \rho(\boldsymbol{A})\).</p> <p>Let \(\tilde{\boldsymbol{A}} = \frac{1}{\varepsilon + \rho(\boldsymbol{A})} \boldsymbol{A}\). It’s easy to see \(\rho(\tilde{\boldsymbol{A}}) &lt; 1\). Then for \(k\) large enough \(\Vert \tilde{\boldsymbol{A}}^k \Vert \le 1 \Leftrightarrow \frac{1}{(\varepsilon + \rho(\boldsymbol{A}))^k} \Vert \boldsymbol{A}^k \Vert \le 1 \Leftrightarrow \Vert \boldsymbol{A}^k \Vert^{1/k} \le \varepsilon + \rho(\boldsymbol{A}).\)</p> <hr> <p><strong>Theorem 2:</strong> For any \(\boldsymbol{A} \ge \boldsymbol{0}\) element-wise and \(\boldsymbol{x} &gt; \boldsymbol{0}\) element-wise,</p> \[\min_{i = 1, \ldots, m} \frac{1}{\boldsymbol{x}_i}\sum_{j=1}^m \boldsymbol{A}_{ij} \boldsymbol{x}_j \le \rho(\boldsymbol{A}) \le \max_{i = 1, \ldots, m} \frac{1}{\boldsymbol{x}_i}\sum_{j=1}^m \boldsymbol{A}_{ij} \boldsymbol{x}_j\] <p><strong>Proof:</strong> Define \(\bar{\boldsymbol{A}} \triangleq \boldsymbol{S}^{-1}\boldsymbol{A}\boldsymbol{S}\), where</p> \[\boldsymbol{S} = \begin{bmatrix} \boldsymbol{x}_1 &amp; &amp; &amp; \\ &amp; \boldsymbol{x}_2 &amp; &amp; \\ &amp; &amp; \ddots &amp; \\ &amp; &amp; &amp; \boldsymbol{x}_m \end{bmatrix},\ \boldsymbol{S}^{-1} = \begin{bmatrix} \frac{1}{\boldsymbol{x}_1} &amp; &amp; &amp; \\ &amp; \frac{1}{\boldsymbol{x}_2} &amp; &amp; \\ &amp; &amp; \ddots &amp; \\ &amp; &amp; &amp; \frac{1}{\boldsymbol{x}_m} \end{bmatrix}.\] <p>\(\rho(\bar{\boldsymbol{A}}) = \rho(\boldsymbol{A})\) as \(\bar{\boldsymbol{A}}\) and \(\boldsymbol{A}\) have same eigenvalues. Apply Lemma 6 to \(\bar{\boldsymbol{A}}\).</p> <p><strong>Corollary 2.1:</strong> For any \(\boldsymbol{A} \ge \boldsymbol{0}\) element-wise and \(\boldsymbol{x} &gt; \boldsymbol{0}\) element-wise, if</p> \[$\alpha \boldsymbol{x} \le \boldsymbol{Ax} \le \beta \boldsymbol{x}\] <p>where \(\alpha, \beta \ge 0\). Then \(\alpha \le \rho(\boldsymbol{A}) \le \beta\). If the inequality is strict, \(\alpha &lt; \rho(\boldsymbol{A}) &lt; \beta\).</p> <p><strong>Proof:</strong></p> \[\begin{align*} \alpha \boldsymbol{x}_i \le \sum_{j=1}^m \boldsymbol{A}_{ij}\boldsymbol{x}_j \Rightarrow \alpha \le \frac{1}{\boldsymbol{x}_i} \sum_{j=1}^m \boldsymbol{A}_{ij}\boldsymbol{x}_j \Rightarrow \alpha \le \min_{i = 1, \ldots, m} \frac{1}{\boldsymbol{x}_i}\sum_{j=1}^m \boldsymbol{A}_{ij} \boldsymbol{x}_j \le \rho(\boldsymbol{A}). \end{align*}\] <p>\(\rho(\boldsymbol{A}) \le \beta\) is similar.</p> <p><strong>Corollary 2.2:</strong> If \(\boldsymbol{A} \ge \boldsymbol{0}\) element-wise and has a eigenvector \(\boldsymbol{x} &gt; \boldsymbol{0}\) element-wise. Then the associated eigenvalue must be \(\rho(\boldsymbol{A})\).</p> <p><strong>Proof:</strong> \(\lambda \boldsymbol{x} \le \boldsymbol{Ax} \le \lambda \boldsymbol{x} \Rightarrow \lambda \le \rho(\boldsymbol{A}) \le \lambda \Rightarrow \rho(\boldsymbol{A}) = \lambda.\)</p> <hr> <p><strong>Theorem 3:</strong> Let \(\boldsymbol{A} &gt; \boldsymbol{0}\) element-wise. Suppose \(\boldsymbol{Ax} = \lambda \boldsymbol{x}\) for some \(\lambda \in \mathbb{R}, \boldsymbol{x} \in \mathbb{R}^{m}\), and \(\vert \lambda \vert = \rho(\boldsymbol{A})\). Then \(\boldsymbol{A} \vert \boldsymbol{x} \vert = \rho(\boldsymbol{A}) \vert \boldsymbol{x} \vert\) and \(\vert \boldsymbol{x} \vert &gt; \boldsymbol{0}\).</p> <p><strong>Proof:</strong> By Corollary 4.1, \(0 &lt; \max_i \boldsymbol{A}_{ii} \le \rho(\boldsymbol{A})\). \(\boldsymbol{Ax} = \lambda\boldsymbol{x} \Rightarrow \vert \boldsymbol{Ax} \vert = \vert \lambda \vert \vert \boldsymbol{x} \vert = \rho(\boldsymbol{A}) \vert \boldsymbol{x} \vert \le \boldsymbol{A} \vert \boldsymbol{x} \vert.\) Define \(\boldsymbol{y} \triangleq \boldsymbol{A} \vert \boldsymbol{x} \vert - \rho(\boldsymbol{A}) \vert \boldsymbol{x} \vert \ge \boldsymbol{0}\) element-wise.</p> <ul> <li>If \(\boldsymbol{y} \equiv \boldsymbol{0}\), i.e., \(\rho(\boldsymbol{A}) \vert \boldsymbol{x} \vert = \boldsymbol{A} \vert \boldsymbol{x} \vert\) element-wise: since \(\boldsymbol{A} \vert \boldsymbol{x} \vert &gt; \boldsymbol{0}\) element-wise and \(0 &lt; \rho(\boldsymbol{A})\), \(\vert \boldsymbol{x} \vert &gt; \boldsymbol{0}\) element-wise.</li> <li>If \(\boldsymbol{y}_i &gt; 0\) for some \(i\), let \(\boldsymbol{z} \triangleq \boldsymbol{A} \vert \boldsymbol{x} \vert &gt; \boldsymbol{0}\) element-wise. Then</li> </ul> \[\begin{align*} &amp;\boldsymbol{0} &lt; \boldsymbol{Ay} = \boldsymbol{A}(\boldsymbol{A} \vert \boldsymbol{x} \vert - \rho(\boldsymbol{A}) \vert \boldsymbol{x} \vert) = \boldsymbol{Az} - \rho(\boldsymbol{A}) \boldsymbol{z} \\ \Rightarrow&amp; \rho(\boldsymbol{A}) \boldsymbol{z} &lt; \boldsymbol{Az} \\ \Rightarrow&amp; \rho(\boldsymbol{A}) &lt; \rho(\boldsymbol{A})\qquad \text{by Corollary 2.1} \end{align*}\] <p>which is a contradiction. So \(\boldsymbol{y} \equiv \boldsymbol{0}\).</p> <hr> <p><strong>Theorem 4:</strong> Let \(\boldsymbol{A} &gt; \boldsymbol{0}\) element-wise. Then \(\forall\ \lambda \ne \rho(\boldsymbol{A}), \vert \lambda \vert &lt; \rho(\boldsymbol{A})\).</p> <p><strong>Proof:</strong> Suppose \(\exists\ \lambda \ne \rho(\boldsymbol{A})\) but \(\vert \lambda \vert = \rho(\boldsymbol{A})\) and \(\boldsymbol{Ax} = \lambda \boldsymbol{x}\). By Lemma 7, \(\exists\ \theta \in \mathbb{R}\) s.t. \(\vert \boldsymbol{x} \vert = e^{-j\theta} \boldsymbol{x} &gt; \boldsymbol{0}\). \(\boldsymbol{Ax} = \lambda \boldsymbol{x} \Rightarrow \boldsymbol{A} \vert \boldsymbol{x} \vert = \lambda \vert \boldsymbol{x} \vert\). By Corollary 2.2 \(\lambda = \rho(\boldsymbol{A})\), which is a contradiction.</p> <hr> <p><strong>Theorem 5:</strong> Let \(\boldsymbol{A} &gt; \boldsymbol{0}\) element-wise. Suppose for two vectors \(\boldsymbol{w}, \boldsymbol{z}\) s.t. \(\boldsymbol{Aw} = \rho(\boldsymbol{A})\boldsymbol{w}, \boldsymbol{Az} = \rho(\boldsymbol{A})\boldsymbol{z}\). Then \(\exists\ \alpha \in \mathbb{C}\) s.t. \(\boldsymbol{w} = \alpha \boldsymbol{z}\), i.e., \(\operatorname{dim}(\operatorname{Null}(\boldsymbol{A} - \rho(\boldsymbol{A})\boldsymbol{I})) = 1\).</p> <p><strong>Proof:</strong> By Lemma 7, \(\exists\ \theta_1, \theta_2\) s.t. \(\boldsymbol{q} = \vert \boldsymbol{w} \vert = e^{-j\theta_1} \boldsymbol{w} &gt; \boldsymbol{0}, \boldsymbol{p} = \vert \boldsymbol{z} \vert = e^{-j\theta_2} \boldsymbol{z} &gt; \boldsymbol{0}\). By Theorem 3 \(\boldsymbol{Aq} = \rho(\boldsymbol{A})\boldsymbol{q}, \boldsymbol{Ap} = \rho(\boldsymbol{A})\boldsymbol{p}\). Let \(\beta = \min_{i=1,\ldots, m} \frac{\boldsymbol{q}_i}{\boldsymbol{p}_i}\) and \(\boldsymbol{r} = \boldsymbol{q} - \beta \boldsymbol{p} \ge \boldsymbol{0}\) with \(\boldsymbol{r}_j = 0\) for some \(j\). Then</p> \[\begin{align*} \boldsymbol{Ar} &amp;= \boldsymbol{Aq} - \beta \boldsymbol{Ap}\\ &amp;= \rho(\boldsymbol{A})\boldsymbol{q} - \beta \rho(\boldsymbol{A})\boldsymbol{p}\\ &amp;= \rho(\boldsymbol{A})\boldsymbol{r} \end{align*}\] <ul> <li>If \(\boldsymbol{r} \equiv \boldsymbol{0}\), then \(\boldsymbol{q} = \beta \boldsymbol{p}\).</li> <li>If \(\boldsymbol{r}_k &gt; 0\) for some \(k\), then \(\boldsymbol{Ar} = \rho(\boldsymbol{A})\boldsymbol{r}&gt;\boldsymbol{0} \Rightarrow \boldsymbol{r} &gt; \boldsymbol{0}\) which is a contradiction.</li> </ul> <p>So \(\boldsymbol{r} = \boldsymbol{0} \Rightarrow \boldsymbol{q} = \beta \boldsymbol{p} \Rightarrow \boldsymbol{w} = \alpha \boldsymbol{z}\).</p> <h2 id="an-application">An application</h2> <p><strong>Irreducible matrix:</strong> Let \(\boldsymbol{A} \in \mathbb{R}^{m \times m}, \boldsymbol{A} \ge \boldsymbol{0}\) element-wise. \(\boldsymbol{A}\) is <em>irreducible</em> if for each index \((i, j), \exists\ k \in \mathbb{N}^+\) s.t. \([\boldsymbol{A}^k]_{ij} &gt; 0\).</p> <p><strong>Subinvariance Theorem:</strong> Let \(\boldsymbol{A} \ge \boldsymbol{0}\) be irreducible. Suppose for some \(\boldsymbol{y} \ge \boldsymbol{0}, \boldsymbol{y} \ne \boldsymbol{0}\) and \(s &gt; 0\), we have \(\boldsymbol{Ay} \le s\boldsymbol{y}\). Then</p> <ol> <li>\(\boldsymbol{y} &gt; \boldsymbol{0}\);</li> <li>\(\rho(\boldsymbol{A}) \le s\);</li> <li>\(\rho(\boldsymbol{A}) = s \iff \boldsymbol{Ay} = s\boldsymbol{y}\).</li> </ol> <p><strong>Proof:</strong></p> <ol> <li>Suppose \(\boldsymbol{y}_i = 0\) for some \(i\), then \(0 \le [\boldsymbol{Ay}]_i \le s \cdot 0 = 0 \Rightarrow [\boldsymbol{Ay}]_i = 0\). Let \(\boldsymbol{z} \triangleq \boldsymbol{Ay}\), then \(\boldsymbol{Az} \le s \boldsymbol{Ay} = s \boldsymbol{z}\). As \(\boldsymbol{z}_i = [\boldsymbol{Ay}]_i = 0, [\boldsymbol{Az}]_i = 0\). Repeat this and we get \([\boldsymbol{A}^k\boldsymbol{y}]_i = 0\) for any \(k\). But for \(k\) large enough \(\boldsymbol{A}^k &gt; \boldsymbol{0}\) which is a contradiction.</li> <li>Corollary 2.1.</li> <li>The “$\Leftarrow$” part is from Corollary 2.1 so we only need to prove the “$\Rightarrow$” part. Suppose \([\boldsymbol{Ay}]_i &lt; s \boldsymbol{y}_i\) for some \(i\). Define \(\boldsymbol{z} = s \boldsymbol{y} - \boldsymbol{Ay} \ge \boldsymbol{0}\) and \(\boldsymbol{z} \ne \boldsymbol{0}\). For \(k\) large enough, \(\boldsymbol{A}^k \boldsymbol{z} = s \boldsymbol{A}^k\boldsymbol{y} - \boldsymbol{A}^k\boldsymbol{Ay} = s \boldsymbol{x} - \boldsymbol{Ax} &gt; \boldsymbol{0}\) where \(\boldsymbol{x} = \boldsymbol{A}^k \boldsymbol{y} &gt; \boldsymbol{0}\). So \(\boldsymbol{Ax} &lt; s \boldsymbol{x} \Rightarrow \rho(\boldsymbol{A}) &lt; s = \rho(\boldsymbol{A})\) by Corollary 2.1, which is a contradiction.</li> </ol> <p><strong>Power control in wireless network:</strong> \(\boldsymbol{A} \ge \boldsymbol{0}\) and is irreducible. \(\boldsymbol{p}, \boldsymbol{b} \in \mathbb{R}^m\) and \(\boldsymbol{b} \ge \boldsymbol{0}\). Suppose \(\boldsymbol{A}, \boldsymbol{b}\) are known, then</p> \[\begin{cases} \boldsymbol{Ap} + \boldsymbol{b} \le \boldsymbol{p} \\ \boldsymbol{p} \ge \boldsymbol{0} \end{cases}\] <p>is feasible w.r.t \(\boldsymbol{p} \iff \rho(\boldsymbol{A}) &lt; 1\).</p> <p><strong>Proof:</strong> The “\(\Leftarrow\)” part. We show \((\boldsymbol{I} - \boldsymbol{A})^{-1}\) exists and \((\boldsymbol{I} - \boldsymbol{A})^{-1} &gt; \boldsymbol{0}\) element-wise, so \(\boldsymbol{p} = (\boldsymbol{I} - \boldsymbol{A})^{-1}\boldsymbol{b}\) is a feasible point.</p> \[(\boldsymbol{I} - \boldsymbol{A}) \lim_{k \to \infty} \sum_{i=0}^k \boldsymbol{A}^k = \lim_{k \to \infty} (\boldsymbol{I} - \boldsymbol{A}^{k+1}) = \boldsymbol{I}.\] <p>\(\lim_{k \to \infty} \boldsymbol{A}^{k+1} = \boldsymbol{0}\) by Lemma 3. So \((\boldsymbol{I} - \boldsymbol{A})^{-1} = \lim_{k \to \infty} \sum_{i=0}^k \boldsymbol{A}^k &gt; \boldsymbol{0}\) since \(\boldsymbol{A}\) is irreducible.</p> <p>The “\(\Rightarrow\)” part. As \(\boldsymbol{b} \ge \boldsymbol{0}\), we have \(\boldsymbol{Ap} \le \boldsymbol{p}, \boldsymbol{p} \ge \boldsymbol{0}\). By Subinvariance Theorem, \(\boldsymbol{p} &gt; \boldsymbol{0}\) and \(\rho(\boldsymbol{A}) \le 1\). If \(\rho(\boldsymbol{A}) = 1\), then \(\boldsymbol{Ap} = \boldsymbol{p}\) which is a contradiction as \(\boldsymbol{b} \ne \boldsymbol{0}\). So \(\rho(\boldsymbol{A}) &lt; 1\).</p> </div> </article> </div> </div> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2023 Tao Deng. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: December 20, 2023. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>